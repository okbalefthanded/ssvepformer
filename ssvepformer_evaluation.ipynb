{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "tS6CbhmEv84f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# set seed\n",
        "seed = 42\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2ie8R1v-QW",
        "outputId": "a35f84be-1c83-41f3-d63c-f913e21ddd49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79c472ad7db0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "Nar2_eP3wMGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "Xg8dyDRkwNpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Download and extract DataSet\n",
        "### Nakanishi et. al 2015\n",
        "!curl -O https://sccn.ucsd.edu/download/cca_ssvep.zip\n",
        "!unzip cca_ssvep.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWixRzhrwRIC",
        "outputId": "4587a1dd-8403-44ed-dfd7-8ffc39c005b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  145M  100  145M    0     0  11.1M      0  0:00:13  0:00:13 --:--:-- 13.2M\n",
            "Archive:  cca_ssvep.zip\n",
            "   creating: cca_ssvep/\n",
            "  inflating: cca_ssvep/s4.mat        \n",
            "  inflating: cca_ssvep/s5.mat        \n",
            "  inflating: cca_ssvep/s3.mat        \n",
            "  inflating: cca_ssvep/s7.mat        \n",
            "  inflating: cca_ssvep/chan_locs.pdf  \n",
            "  inflating: cca_ssvep/readme.txt    \n",
            "  inflating: cca_ssvep/s2.mat        \n",
            "  inflating: cca_ssvep/s8.mat        \n",
            "  inflating: cca_ssvep/s10.mat       \n",
            "  inflating: cca_ssvep/s9.mat        \n",
            "  inflating: cca_ssvep/s6.mat        \n",
            "  inflating: cca_ssvep/s1.mat        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "QSif6Y2swY2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing\n",
        "def segment_eeg(folder, elecs=None, fs=256, duration=1., band=[5., 45.], order=4, onset=0.135):\n",
        "  eeg_files = glob.glob(f\"{data_folder}/*.mat\")\n",
        "  n_subejects = len(eeg_files)\n",
        "  onset = 38 + int(onset*fs)\n",
        "  end = int(duration*fs)\n",
        "  X , Y = [], [] # empty data and labels\n",
        "  for record in eeg_files:\n",
        "    data = loadmat(record)\n",
        "    # samples, channels, trials, targets\n",
        "    eeg = data[\"eeg\"].transpose((2, 1, 3, 0))\n",
        "    # filter data\n",
        "    eeg = filter_eeg(eeg, fs=fs, band=band, order=order)\n",
        "    # segment data\n",
        "    eeg = eeg[onset:onset+end, :, :, :]\n",
        "    samples, channels, blocks, targets = eeg.shape\n",
        "    y = np.tile(np.arange(1, targets + 1), (blocks, 1))\n",
        "    y = y.reshape((1, blocks * targets), order='F')\n",
        "\n",
        "    X.append(eeg.reshape((samples, channels, blocks * targets), order='F'))\n",
        "    Y.append(y)\n",
        "\n",
        "  X = np.array(X, dtype=np.float32, order=\"F\")\n",
        "  Y = np.array(Y, dtype=np.float32).squeeze()\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "def filter_eeg(data, fs=256, band=[5., 45.], order=4, axis=0):\n",
        "  B, A = butter(order, np.array(band) / (fs / 2), btype='bandpass')\n",
        "  return filtfilt(B, A, data, axis=axis)"
      ],
      "metadata": {
        "id": "Og4Scc69v0GO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "d_QLu_GIwpoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment data into epochs"
      ],
      "metadata": {
        "id": "PUQKT6tTwrK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = os.path.abspath('./cca_ssvep')\n",
        "band = [8, 64]\n",
        "order = 4\n",
        "fs = 256\n",
        "duration = 1.\n",
        "\n",
        "X, Y = segment_eeg(data_folder, band=band, order=order, fs=fs, duration=duration)\n",
        "print(f\"X shape: {X.shape}\") # subject x samples x channels x trials\n",
        "print(f\"Y shape: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYLjycbRwc3i",
        "outputId": "64931ca3-6c2c-4e24-9cda-1eae6d04455b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (10, 256, 8, 180)\n",
            "Y shape: (10, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "3XdrU_kmwtlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import flatten\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChComb(nn.Module):\n",
        "  def __init__(self, Chans=8, Samples=220, dropout=0.5):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv1d(Chans // 2, Chans, 1, padding='same')\n",
        "    self.ln   = nn.LayerNorm(Samples)\n",
        "    self.act  = nn.GELU()\n",
        "    self.do   = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.do(self.act(self.ln(self.conv(x))))\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, Chans=16, Samples=220, dropout=0.5):\n",
        "    super().__init__()\n",
        "    # CNN module\n",
        "    self.channels = Chans\n",
        "    self.ln1  = nn.LayerNorm(Samples)\n",
        "    self.conv = nn.Conv1d(Chans, Chans, 31, padding='same')\n",
        "    self.ln2  = nn.LayerNorm(Samples)\n",
        "    self.act  = nn.GELU()\n",
        "    self.do   = nn.Dropout(p=dropout)\n",
        "    # MLP module\n",
        "    self.ln3  = nn.LayerNorm(Samples)\n",
        "    self.proj = nn.Linear(Chans, Samples)\n",
        "    self.do2  = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #\n",
        "    shortcut1 = x\n",
        "    x = self.conv(self.ln1(x))\n",
        "    x = self.act(self.ln2(x))\n",
        "    x = self.do(x) + shortcut1\n",
        "    shortcut2 = x\n",
        "    #\n",
        "    x = self.ln3(x)\n",
        "    output_channels = []\n",
        "    for i in range(self.channels):\n",
        "      c = self.proj(x[:,:,i])\n",
        "      c = c.unsqueeze(1)\n",
        "      output_channels.append(c)\n",
        "    x = torch.cat(output_channels, 1)\n",
        "    x = self.do(x) + shortcut2\n",
        "    return x\n",
        "\n",
        "class MlpHead(nn.Module):\n",
        "  def __init__(self, Chans, Samples, n_classes, drop_rate=0.5):\n",
        "    super().__init__()\n",
        "    self.drop       = nn.Dropout(drop_rate)\n",
        "    self.linear1    = nn.Linear(Chans * Samples, 6 * n_classes)\n",
        "    self.norm       = nn.LayerNorm(6*n_classes)\n",
        "    self.activation = nn.GELU()\n",
        "    self.drop2      = nn.Dropout(drop_rate)\n",
        "    self.linear2    = nn.Linear(6*n_classes, n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = flatten(x, 1)\n",
        "    x = self.drop(x)\n",
        "    x = self.linear1(x)\n",
        "    x = self.norm(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.drop2(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n",
        "\n",
        "class SSVEPFormerTH(nn.Module):\n",
        "  def __init__(self, Chans=8, n_classes=12, fs=256,\n",
        "               band=[8, 64], resolution=0.25,\n",
        "               drop_rate=0.25):\n",
        "    super().__init__()\n",
        "    self.name = \"SSVEPFORMER\"\n",
        "    self.fs = fs\n",
        "    self.resolution = resolution\n",
        "    self.nfft  = round(fs / resolution)\n",
        "    self.fft_start = int(round(band[0] / self.resolution))\n",
        "    self.fft_end   = int(round(band[1] / self.resolution)) + 1\n",
        "    samples = (self.fft_end - self.fft_start) * 2\n",
        "    filters = 2*Chans\n",
        "\n",
        "    self.channel_comb = ChComb(filters,  samples, drop_rate)\n",
        "    self.encoder1     = Encoder(filters, samples, drop_rate)\n",
        "    self.encoder2     = Encoder(filters, samples, drop_rate)\n",
        "    self.head         = MlpHead(filters, samples, n_classes, drop_rate)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    for module in self.modules():\n",
        "        if hasattr(module, 'weight'):\n",
        "          cls_name = module.__class__.__name__\n",
        "          if not(\"BatchNorm\" in cls_name or \"LayerNorm\" in cls_name):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.01)\n",
        "          else:\n",
        "            nn.init.constant_(module.weight, 1)\n",
        "          if hasattr(module, \"bias\"):\n",
        "            if module.bias is not None:\n",
        "              nn.init.constant_(module.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.transform(x)\n",
        "    x = self.channel_comb(x)\n",
        "    x = self.encoder1(x)\n",
        "    x = self.encoder2(x)\n",
        "    x = self.head(x)\n",
        "    return x\n",
        "\n",
        "  def transform(self, x):\n",
        "    with torch.no_grad():\n",
        "      samples = x.shape[-1]\n",
        "      x = torch.fft.fft(x, n=self.nfft) / samples\n",
        "      real = x.real[:,:, self.fft_start:self.fft_end]\n",
        "      imag = x.imag[:,:, self.fft_start:self.fft_end]\n",
        "      x = torch.cat((real, imag), axis=-1)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "icZUf4TgwvAc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FBSSVEPFormer(nn.Module):\n",
        "  def __init__(self, fs=256, n_subbands=3, models=None):\n",
        "    super().__init__()\n",
        "    self.name = \"FB-SSVEPFORMER\"\n",
        "    self.fs = fs\n",
        "    self.subbands = [[8*i, 80] for i in range(1, n_subbands+1)]\n",
        "    self.subnets = models\n",
        "    self.conv = nn.Conv1d(n_subbands, 1, 1, padding='same')\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    nn.init.normal_(self.conv.weight, mean=0.0, std=0.01)\n",
        "    nn.init.constant_(self.conv.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = []\n",
        "    for i, band in enumerate(self.subbands):\n",
        "      c = self.filter_band(x, band)\n",
        "      c = self.subnets[i](c)\n",
        "      c = c.unsqueeze(1)\n",
        "      out.append(c)\n",
        "    #\n",
        "    x = torch.cat(out, 1)\n",
        "    x = self.conv(x)\n",
        "    return x.squeeze(1)\n",
        "\n",
        "  def filter_band(self, x, band):\n",
        "    # x: batch, channels, samples\n",
        "    device = x.device\n",
        "    with torch.no_grad():\n",
        "      x = x.cpu().numpy()\n",
        "      B, A = butter(4, np.array(band) / (self.fs / 2), btype='bandpass')\n",
        "      x = filtfilt(B, A, x, axis=-1)\n",
        "      x = x.copy()\n",
        "    return torch.tensor(x, dtype=torch.float, device=device)\n",
        "\n"
      ],
      "metadata": {
        "id": "ulJzt2OyJaS2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils for training"
      ],
      "metadata": {
        "id": "Vt6Z2uavxsye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(x, y, batch_size=32, shuffle=True):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    tensor_set = torch.utils.data.TensorDataset(torch.tensor(x, dtype=torch.float32),\n",
        "                                                torch.tensor(y, dtype=torch.long))\n",
        "    loader = torch.utils.data.DataLoader(tensor_set,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=shuffle)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "uSfgiU4DzQaQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Pytorch training loop\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, epochs):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch % 100 == 0:\n",
        "                loss, current = loss.item(), (batch + 1) * len(X)\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    return 100*correct"
      ],
      "metadata": {
        "id": "W2ofx5TGynth"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_subjects(x, y, fold):\n",
        "  X = np.concatenate([x[idx] for idx in fold], axis=-1)\n",
        "  Y = np.concatenate([y[idx] for idx in fold], axis=-1)\n",
        "  X  = X.transpose((2,1,0))\n",
        "  return X, Y - 1"
      ],
      "metadata": {
        "id": "pORsiiAMxPRe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing"
      ],
      "metadata": {
        "id": "s7HTFLovxvvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, x_train, y_train, x_val, y_val, band):\n",
        "    x  = filter_eeg(x_train, fs=256, band=band, order=4, axis=-1)\n",
        "    xv = filter_eeg(x_val, fs=256, band=band, order=4, axis=-1)\n",
        "    x = x.copy()\n",
        "    xv = xv.copy()\n",
        "\n",
        "    # Create data loaders.\n",
        "    train_dataloader = make_loader(x, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_dataloader  = make_loader(xv, y_val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    model.init_weights()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                lr=LR,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=WD, nesterov=False)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train(train_dataloader, model, loss_fn, optimizer, EPOCHS)\n",
        "\n",
        "    acc = test(test_dataloader, model, loss_fn)\n",
        "    print(f\"Accuracy: {acc}\")\n",
        "\n",
        "def freeze_model(model):\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "c3jAeoM7JvBs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "LR = 0.001\n",
        "WD = 0.001\n",
        "DROP_RATE = 0.5\n",
        "\n",
        "channels  = 8\n",
        "n_classes = 12\n",
        "fft_resolution = 0.25\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "5id4uL6d0swG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.zeros((10, 1))\n",
        "\n",
        "for subject in range(0, 10):\n",
        "    print(f\"Subject: {subject + 1} Training...\")\n",
        "\n",
        "    folds = np.delete(np.arange(10), subject)\n",
        "    train_index = folds\n",
        "    test_index  = [subject]\n",
        "\n",
        "    # create data split for each subject\n",
        "    x_train, y_train = concatenate_subjects(X, Y, train_index)\n",
        "    x_val, y_val     = concatenate_subjects(X, Y, test_index)\n",
        "\n",
        "    # Create data loaders.\n",
        "    train_dataloader = make_loader(x_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_dataloader  = make_loader(x_val, y_val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # create model\n",
        "    model = SSVEPFormerTH(Chans=channels,\n",
        "                           n_classes=n_classes,\n",
        "                           fs=fs,\n",
        "                           band=band,\n",
        "                           resolution=fft_resolution,\n",
        "                           drop_rate=DROP_RATE)\n",
        "    model.init_weights()\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                lr=LR,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=WD, nesterov=False)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train(train_dataloader, model, loss_fn, optimizer, EPOCHS)\n",
        "\n",
        "    acc[subject] = test(test_dataloader, model, loss_fn)\n",
        "    print(f\"Subhject {subject+1} Accuracy: {acc[subject]}\")\n",
        "    print(\"-------------------------------\")\n",
        "\n",
        "print(f\"Mean Accuracy: {np.mean(acc)} +- {np.std(acc)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_dWkkGXxWoW",
        "outputId": "9647f0f3-60bd-4c6f-a52a-33a8b9e2f489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: 1 Training...\n",
            "Subhject 1 Accuracy: [87.77777778]\n",
            "-------------------------------\n",
            "Subject: 2 Training...\n",
            "Subhject 2 Accuracy: [97.77777778]\n",
            "-------------------------------\n",
            "Subject: 3 Training...\n",
            "Subhject 3 Accuracy: [96.11111111]\n",
            "-------------------------------\n",
            "Subject: 4 Training...\n",
            "Subhject 4 Accuracy: [95.]\n",
            "-------------------------------\n",
            "Subject: 5 Training...\n",
            "Subhject 5 Accuracy: [56.11111111]\n",
            "-------------------------------\n",
            "Subject: 6 Training...\n",
            "Subhject 6 Accuracy: [56.66666667]\n",
            "-------------------------------\n",
            "Subject: 7 Training...\n",
            "Subhject 7 Accuracy: [94.44444444]\n",
            "-------------------------------\n",
            "Subject: 8 Training...\n",
            "Subhject 8 Accuracy: [97.22222222]\n",
            "-------------------------------\n",
            "Subject: 9 Training...\n",
            "Subhject 9 Accuracy: [66.11111111]\n",
            "-------------------------------\n",
            "Subject: 10 Training...\n",
            "Subhject 10 Accuracy: [98.88888889]\n",
            "-------------------------------\n",
            "Mean Accuracy: 84.61111111111111 +- 16.788535918048506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = np.zeros((10, 1))\n",
        "subbands = 3\n",
        "bands = [ [8*i, 80] for i in range(1, subbands+1)]\n",
        "\n",
        "for subject in range(0, 10):\n",
        "    print(f\"Subject: {subject + 1} Training...\")\n",
        "\n",
        "    folds = np.delete(np.arange(10), subject)\n",
        "    train_index = folds\n",
        "    test_index  = [subject]\n",
        "\n",
        "    # create data split for each subject\n",
        "    x_train, y_train = concatenate_subjects(X, Y, train_index)\n",
        "    x_val, y_val     = concatenate_subjects(X, Y, test_index)\n",
        "\n",
        "    # Create data loaders.\n",
        "    train_dataloader = make_loader(x_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_dataloader  = make_loader(x_val, y_val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    models = [SSVEPFormerTH(Chans=channels,\n",
        "                           n_classes=n_classes,\n",
        "                           fs=fs,\n",
        "                           band=b,\n",
        "                           resolution=fft_resolution,\n",
        "                           drop_rate=DROP_RATE) for b in bands]\n",
        "\n",
        "    for mod, b in zip(models, bands):\n",
        "        train_model(mod, x_train, y_train, x_val, y_val, b)\n",
        "        freeze_model(mod)\n",
        "\n",
        "\n",
        "    # create model\n",
        "    model = FBSSVEPFormer(fs=256, n_subbands=3, models=models)\n",
        "    model.init_weights()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                lr=LR,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=WD, nesterov=False)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train(train_dataloader, model, loss_fn, optimizer, 20)\n",
        "\n",
        "    acc[subject] = test(test_dataloader, model, loss_fn)\n",
        "    print(f\"Subhject {subject+1} Accuracy: {acc[subject]}\")\n",
        "    print(\"-------------------------------\")\n",
        "\n",
        "print(f\"Mean Accuracy: {np.mean(acc)} +- {np.std(acc)}\")"
      ],
      "metadata": {
        "id": "uNRwNSqL4S3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237fa0b9-3449-44b4-cb93-76be82edae4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: 1 Training...\n",
            "Accuracy: 96.66666666666667\n",
            "Accuracy: 44.44444444444444\n",
            "Accuracy: 60.55555555555555\n",
            "Subhject 1 Accuracy: [96.66666667]\n",
            "-------------------------------\n",
            "Subject: 2 Training...\n",
            "Accuracy: 98.88888888888889\n",
            "Accuracy: 85.55555555555556\n",
            "Accuracy: 50.55555555555556\n",
            "Subhject 2 Accuracy: [100.]\n",
            "-------------------------------\n",
            "Subject: 3 Training...\n",
            "Accuracy: 94.44444444444444\n",
            "Accuracy: 87.22222222222223\n",
            "Accuracy: 92.77777777777779\n",
            "Subhject 3 Accuracy: [97.77777778]\n",
            "-------------------------------\n",
            "Subject: 4 Training...\n",
            "Accuracy: 46.666666666666664\n",
            "Accuracy: 29.444444444444446\n",
            "Accuracy: 20.555555555555554\n",
            "Subhject 4 Accuracy: [49.44444444]\n",
            "-------------------------------\n",
            "Subject: 5 Training...\n",
            "Accuracy: 88.33333333333333\n",
            "Accuracy: 57.77777777777777\n",
            "Accuracy: 40.55555555555556\n",
            "Subhject 5 Accuracy: [83.88888889]\n",
            "-------------------------------\n",
            "Subject: 6 Training...\n",
            "Accuracy: 94.44444444444444\n",
            "Accuracy: 87.22222222222223\n",
            "Accuracy: 70.55555555555556\n",
            "Subhject 6 Accuracy: [98.33333333]\n",
            "-------------------------------\n",
            "Subject: 7 Training...\n",
            "Accuracy: 96.11111111111111\n",
            "Accuracy: 89.44444444444444\n",
            "Accuracy: 68.33333333333333\n",
            "Subhject 7 Accuracy: [100.]\n",
            "-------------------------------\n",
            "Subject: 8 Training...\n",
            "Accuracy: 51.66666666666667\n",
            "Accuracy: 54.44444444444444\n",
            "Accuracy: 45.0\n",
            "Subhject 8 Accuracy: [65.55555556]\n",
            "-------------------------------\n",
            "Subject: 9 Training...\n",
            "Accuracy: 63.33333333333333\n",
            "Accuracy: 75.0\n",
            "Accuracy: 72.22222222222221\n",
            "Subhject 9 Accuracy: [85.]\n",
            "-------------------------------\n",
            "Subject: 10 Training...\n",
            "Accuracy: 96.11111111111111\n",
            "Accuracy: 86.66666666666667\n",
            "Accuracy: 87.77777777777777\n",
            "Subhject 10 Accuracy: [99.44444444]\n",
            "-------------------------------\n",
            "Mean Accuracy: 87.61111111111111 +- 16.465545770816835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-treC7hop-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}